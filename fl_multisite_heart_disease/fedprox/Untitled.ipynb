{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe696e-a65d-4d2e-99e7-58316e6badd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "GLOBAL_METRICS_FILE = \"./global_metrics.csv\"\n",
    "CLIENT_METRICS_FILE = \"./client_metrics.csv\"\n",
    "FINAL_ROUND_CLIENT_COUNT = 12 # Adjust if your client count changes\n",
    "\n",
    "def generate_fl_plots():\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df_global = pd.read_csv(GLOBAL_METRICS_FILE)\n",
    "        df_client = pd.read_csv(CLIENT_METRICS_FILE)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Ensure both CSV files are in the current directory.\")\n",
    "        return\n",
    "\n",
    "    # --- Data Cleaning and Aggregation ---\n",
    "    \n",
    "    # Filter client data to only include evaluation metrics (local test set)\n",
    "    df_client_eval = df_client[df_client['phase'] == 'evaluate'].copy()\n",
    "    \n",
    "    # Calculate the average client accuracy for each round\n",
    "    df_avg_client_acc = df_client_eval.groupby('round')['accuracy'].mean().reset_index()\n",
    "    df_avg_client_acc.rename(columns={'accuracy': 'avg_client_accuracy'}, inplace=True)\n",
    "    \n",
    "    # Find the maximum round for final round analysis\n",
    "    max_round = df_global['round'].max()\n",
    "    print(f\"Data loaded successfully. Max round found: {max_round}\")\n",
    "\n",
    "    # ====================================================================\n",
    "    # PLOT 1: Global Convergence vs. Average Client Performance\n",
    "    # ====================================================================\n",
    "    \n",
    "    # Merge global metrics and average client metrics\n",
    "    df_combined = pd.merge(df_global, df_avg_client_acc, on='round', how='inner')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Global Accuracy\n",
    "    plt.plot(df_combined['round'], df_combined['accuracy'], \n",
    "             label='Global Model Accuracy (FedAvg)', \n",
    "             marker='o', linestyle='-', color='blue')\n",
    "    \n",
    "    # Plot Average Client Accuracy\n",
    "    plt.plot(df_combined['round'], df_combined['avg_client_accuracy'], \n",
    "             label='Average Local Client Accuracy', \n",
    "             marker='s', linestyle='--', color='red', alpha=0.7)\n",
    "    \n",
    "    plt.title('FL Convergence: Global Model vs. Average Client Accuracy Over Rounds', fontsize=14)\n",
    "    plt.xlabel('Server Round', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.xticks(np.arange(0, max_round + 1, 2)) # Show every 2nd round\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('global_convergence_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Generated plot: global_convergence_plot.png\")\n",
    "\n",
    "    # ====================================================================\n",
    "    # PLOT 2: Client Heterogeneity (Final Round Performance)\n",
    "    # ====================================================================\n",
    "\n",
    "    # Filter data for the final evaluation round\n",
    "    df_final_round = df_client_eval[df_client_eval['round'] == max_round].sort_values(by='cid')\n",
    "\n",
    "    # Convert cid to integer for cleaner plotting\n",
    "    df_final_round['cid'] = df_final_round['cid'].astype(int)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create the Bar Plot\n",
    "    bars = plt.bar(df_final_round['cid'].apply(lambda x: f'Client {x}'), \n",
    "                   df_final_round['accuracy'], \n",
    "                   color='teal')\n",
    "    \n",
    "    # Add the Global Model Accuracy line for comparison\n",
    "    global_acc_final = df_global[df_global['round'] == max_round]['accuracy'].iloc[0]\n",
    "    plt.axhline(global_acc_final, color='red', linestyle='--', \n",
    "                label=f'Global Accuracy ({global_acc_final:.4f})', linewidth=2)\n",
    "    \n",
    "    # Label the bars with their accuracy values\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, \n",
    "                 f'{yval:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.title(f'Client Performance Heterogeneity (Round {max_round})', fontsize=14)\n",
    "    plt.xlabel('Client ID', fontsize=12)\n",
    "    plt.ylabel('Local Validation Accuracy', fontsize=12)\n",
    "    plt.ylim(0, 1) # Set Y-axis from 0 to 1 for accuracy visualization\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('client_heterogeneity_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Generated plot: client_heterogeneity_plot.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_fl_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e599f4-f383-4797-b94a-8afcbe5c3b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "GLOBAL_METRICS_FILE = \"./global_metrics.csv\"\n",
    "CLIENT_METRICS_FILE = \"./client_metrics.csv\"\n",
    "FINAL_ROUND_CLIENT_COUNT = 12 # Adjust if your client count changes\n",
    "\n",
    "\n",
    "try:\n",
    "    df_global = pd.read_csv(GLOBAL_METRICS_FILE)\n",
    "    df_client = pd.read_csv(CLIENT_METRICS_FILE)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Ensure both CSV files are in the current directory.\")\n",
    "    return\n",
    "\n",
    "# --- Data Cleaning and Aggregation ---\n",
    "\n",
    "# Filter client data to only include evaluation metrics (local test set)\n",
    "df_client_eval = df_client[df_client['phase'] == 'evaluate'].copy()\n",
    "\n",
    "# Calculate the average client accuracy for each round\n",
    "df_avg_client_acc = df_client_eval.groupby('round')['accuracy'].mean().reset_index()\n",
    "df_avg_client_acc.rename(columns={'accuracy': 'avg_client_accuracy'}, inplace=True)\n",
    "\n",
    "# Find the maximum round for final round analysis\n",
    "max_round = df_global['round'].max()\n",
    "print(f\"Data loaded successfully. Max round found: {max_round}\")\n",
    "\n",
    "\n",
    "# ====================================================================\n",
    "# PLOT 2: Client Heterogeneity (Final Round Performance)\n",
    "# ====================================================================\n",
    "\n",
    "# Filter data for the final evaluation round\n",
    "df_final_round = df_client_eval[df_client_eval['round'] == max_round].sort_values(by='cid')\n",
    "\n",
    "# Convert cid to integer for cleaner plotting\n",
    "df_final_round['cid'] = df_final_round['cid'].astype(int)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the Bar Plot\n",
    "bars = plt.bar(df_final_round['cid'].apply(lambda x: f'Client {x}'), \n",
    "               df_final_round['accuracy'], \n",
    "               color='teal')\n",
    "\n",
    "# Add the Global Model Accuracy line for comparison\n",
    "global_acc_final = df_global[df_global['round'] == max_round]['accuracy'].iloc[0]\n",
    "plt.axhline(global_acc_final, color='red', linestyle='--', \n",
    "            label=f'Global Accuracy ({global_acc_final:.4f})', linewidth=2)\n",
    "\n",
    "# Label the bars with their accuracy values\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, \n",
    "             f'{yval:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title(f'Client Performance Heterogeneity (Round {max_round})', fontsize=14)\n",
    "plt.xlabel('Client ID', fontsize=12)\n",
    "plt.ylabel('Local Validation Accuracy', fontsize=12)\n",
    "plt.ylim(0, 1) # Set Y-axis from 0 to 1 for accuracy visualization\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7a2dd-636f-4c72-8e5b-c6210795add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('client_heterogeneity_plotv2.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Generated plot: client_heterogeneity_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
